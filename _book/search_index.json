[["index.html", "Power BI for M&amp;E and Public Health Data Analysts Preface 0.1 Author’s Note 0.2 The Gap in Data Training 0.3 Who This Guide Is For 0.4 How to Use This Guide", " Power BI for M&amp;E and Public Health Data Analysts Oluwatobi Olatunbosun (c)2025 Preface 0.1 Author’s Note This book was written from lived experience.It is an independent work authored in a personal capacity. Over the years, I have worked with Monitoring and Evaluation teams, data managers, and program leads across public health and development programs who are under constant pressure to produce timely, accurate, and actionable reports. In many of these settings, Power BI is introduced as a tool, but not as a system for thinking about data use. This guide exists to close that gap. Rather than teaching Power BI as a collection of buttons and visuals, I focus on the underlying principles that make dashboards reliable, scalable, and trusted. The examples in this book are drawn from real program realities, using synthetic data designed to reflect the complexity and imperfections of health information systems. My hope is that this resource helps you move beyond reporting and toward meaningful, confident data use. — Oluwatobi Olatunbosun O.O 0.2 The Gap in Data Training If you search for Power BI tutorials online, you will find thousands of examples built around sales revenue, customer churn, and profit margins. These examples are useful, but they are designed for a world where data is clean, definitions are stable, and success is measured primarily in financial terms. That is not the reality for most Monitoring and Evaluation or Public Health professionals. In practice, we work with patients, communities, and health facilities. Our data comes from multiple systems that rarely speak to each other. Definitions vary by donor, reporting cycle, and program area. We do not track profit. We track coverage, outcomes, service quality, and impact, often under tight reporting timelines and with imperfect data. As a result, many professionals learn Power BI in theory but struggle to apply it in real program settings. Dashboards look impressive but break when indicators change. Numbers differ across reports. Teams spend more time fixing spreadsheets than using data to guide decisions. This guide exists to bridge that gap. It takes proven Power BI practices from the corporate analytics world and translates them into the context of development programs, health systems, and population-level data. The focus is not on decorative visuals, but on building reliable, reusable, and trusted analytical systems that reflect how public health data actually works. The goal is simple: to help you move from reporting numbers to using data with confidence. 0.3 Who This Guide Is For This guide is written for professionals working with data in development and public health programs who require tools that function effectively in real-world conditions. It is particularly relevant for: Monitoring and Evaluation Officers Who are responsible for producing routine reports and dashboards, and are tired of manually updating Excel files every reporting cycle. If you spend more time cleaning data and fixing formulas than interpreting results, this guide is written with your workflow in mind. Data Managers and Health Information Officers Who work with data from multiple systems such as KoboToolbox, ODK, DHIS2, laboratory systems, and electronic medical records. If your role involves harmonizing datasets, resolving inconsistencies, and ensuring data quality across sources, this guide focuses on building repeatable and defensible processes. Program Managers and Technical Leads Who rely on data to track performance, identify gaps, and make programmatic decisions. If static PDF reports arrive too late to influence action, this guide demonstrates how interactive dashboards can support timely and informed decision-making. No prior Power BI expertise is assumed. Concepts are introduced progressively, with practical examples designed to build confidence for beginners while reinforcing best practices for experienced users. 0.4 How to Use This Guide The book follows a simple and practical data lifecycle that mirrors real project workflows: Orientation Understanding the Power BI ecosystem and how its components fit together. Preparation (ETL) Extracting data from common sources and applying repeatable data cleaning patterns. Modeling Structuring data correctly to support accurate analysis and long-term reuse. Analytics Using DAX to calculate indicators, rates, ratios, and trends commonly used in M&amp;E and Public Health. Storytelling Designing dashboards that communicate clearly and support action. Each chapter builds on the previous one. You can read the book sequentially or jump directly to the section that matches your current needs. © 2025 All rights reserved. "],["prerequisites.html", "Prerequisites 0.5 Software Requirements 0.6 Hardware Recommendations 0.7 Data Used in This Book 0.8 Files You Will Work With 0.9 Knowledge Assumptions 0.10 How This Book Is Organized 0.11 Before You Continue", " Prerequisites This chapter outlines what you need before working through the rest of this book. The goal is to ensure that all readers start from a shared baseline, regardless of prior experience. Nothing here is advanced. If you can open Power BI Desktop and follow simple instructions, you are ready. 0.5 Software Requirements 0.5.1 Power BI Desktop You must have Power BI Desktop installed. Platform: Windows 10 or 11 Version: Latest stable release (updated monthly) Download: powerbi.microsoft.com/desktop All examples, screenshots, and exercises in this book use Power BI Desktop. Note on Licensing: Power BI Desktop is free. A paid Power BI Pro license is not required to follow the exercises in this book. 0.5.2 A Note for Mac Users Power BI Desktop does not run natively on macOS. If you are using a Mac, you have two options: 1. Install Windows on your Mac using a virtual machine (e.g., Parallels or VMWare). 2. Use a Windows 365 Cloud PC. 0.6 Hardware Recommendations Power BI is an in-memory tool. For the best experience: * RAM: 8 GB minimum (16 GB recommended). * Screen: A second monitor is highly recommended (one screen for this book, one screen for Power BI). 0.7 Data Used in This Book All practical exercises use a synthetic, patient-level integrated health dataset created specifically for learning. The dataset represents routine service delivery across: - Antenatal Care (ANC) - HIV and ART - Malaria - Tuberculosis (TB) - Non-Communicable Diseases (NCDs) Privacy Note: No real patient data is used. All names and IDs are randomly generated. The dataset is intentionally not clean. It includes missing values, inconsistent formats, and common data quality issues that reflect real health information systems. You will clean, model, and analyze this data step by step in later chapters. 0.8 Files You Will Work With You should have access to the project folder containing the following CSV files: fact_patient_visits.csv (The transactional line list) dim_patient.csv (Demographics) dim_facility.csv (Locations and ownership) dim_date.csv (Reporting periods) These files form a simple star-schema structure that will be used throughout the book. Important: Do not edit these files manually in Excel. All cleaning and transformation will be done inside Power BI. 0.9 Knowledge Assumptions This book assumes: - Basic familiarity with tables (rows and columns). - Comfort opening files and using software menus. - No prior Power BI experience. - No prior DAX experience. - No database background. If you have used Excel for reporting (even just for simple sums and filters), you are more than prepared. 0.10 How This Book Is Organized Each chapter builds on the previous one. Concept &amp; Structure: Understanding the “Why” and the ecosystem. Preparation (ETL): Getting messy data ready for analysis. Modeling: Building the relationships (Star Schema). Analytics: Using DAX for indicators. Storytelling: Visualizing data for decision support. Practical exercises are included in most chapters. You are encouraged to follow along in Power BI rather than reading passively. 0.11 Before You Continue Before moving to the next chapter, confirm that: [ ] Power BI Desktop opens successfully without errors. [ ] You can locate the sample CSV files on your computer. [ ] You have created a folder (e.g., My Power BI Project) to save your work. Once these are in place, you are ready to begin. The next chapter explains why Power BI matters for Monitoring and Evaluation, and how it fits into real program workflows. "],["why-power-bi-matters-for-data-use.html", "Chapter: 1 Why Power BI Matters for Data Use 1.1 Data Use Is Not the Same as Reporting 1.2 The Problem with the Excel Cycle 1.3 What Power BI Changes Fundamentally 1.4 Scale Matters in Public Health and M&amp;E 1.5 Security and Responsible Data Access 1.6 Power BI as a Data Use Enabler 1.7 What This Means for the Rest of This Guide", " Chapter: 1 Why Power BI Matters for Data Use In the development and public health sector, data is abundant but rarely usable in the moment decisions need to be made. Financial data may live in one system, facility targets in Excel files, survey results in KoboToolbox or ODK, and service delivery data in platforms such as DHIS2 or electronic medical records. Each system works in isolation. The result is not a data shortage, but a data use problem. Teams spend more time preparing data than actually analysing it. By the time reports are produced, the opportunity to act may already have passed. Power BI matters because it directly addresses this gap between data availability and data use. 1.1 Data Use Is Not the Same as Reporting In many organisations, reporting and data use are treated as the same thing. They are not. Reporting focuses on Submitting figures on time, Meeting donor or regulatory requirements, Producing static tables and charts while Data use focuses on Understanding trends and patterns, Identifying gaps early,Supporting operational and strategic decisions Most traditional reporting workflows are retrospective. They tell you what happened last month or last quarter. Effective data use, however, supports continuous monitoring, allowing teams to identify issues while there is still time to respond. Power BI is designed for this second purpose. 1.2 The Problem with the Excel Cycle Most Monitoring and Evaluation teams operate in a familiar manual loop: Export data from the server on the 5th of the month. Spend several days cleaning it in Excel by fixing dates, removing extra headers, and correcting formats. Copy and paste the cleaned data into a “master dashboard” file. Email the file to multiple stakeholders. Repeat the same process the following month. This cycle feels productive because it produces outputs. In reality, it introduces several hidden risks. Human error increases with every manual step. Inconsistencies arise when different people clean data differently. Delays mean decisions are based on outdated information. Fatigue sets in as teams repeat the same work every reporting period. Excel is a powerful tool, but it was never designed to serve as a scalable monitoring system. Note: Manual Excel workflows also make audit trails weak, since transformation logic often exists only in someone’s memory or personal file. 1.3 What Power BI Changes Fundamentally Power BI does not simply create better charts. It changes how data workflows are designed and maintained. From Manual to Automated Workflows In Power BI, data preparation steps are defined once using Power Query. These steps are saved, documented, and reused. Instead of rebuilding dashboards every month, teams refresh data using the same logic. This shift alone can save days of effort per reporting cycle. From Static Files to Live Models Excel dashboards are usually copies of data frozen in time. Power BI works with a data model that can be refreshed regularly. This enables: More frequent updates Consistent indicator definitions Reuse of the same model across multiple reports When the model is correct, dashboards become lightweight views rather than separate files to manage. From Individual Files to Shared Truth In Excel-based reporting, it is common for different stakeholders to have slightly different versions of the same report. Power BI introduces a shared source of truth: One dataset One set of indicator definitions Multiple audiences accessing the same numbers This improves trust in the data and reduces time spent reconciling discrepancies. 1.4 Scale Matters in Public Health and M&amp;E Health and development data grows quickly. Line lists, facility-level reporting, and longitudinal patient records can easily exceed what Excel can reliably handle. As datasets grow, performance issues and file instability become common. Power BI is built to: Compress large datasets efficiently Handle millions of rows Support complex relationships between tables This makes it suitable for national programs, multi-partner projects, and long-term monitoring systems. 1.5 Security and Responsible Data Access Public health and M&amp;E data often contains sensitive information. Emailing Excel files creates unnecessary risk. Files can be forwarded, copied, or stored without proper controls. Power BI supports: Secure access through user accounts Role-based permissions Row-Level Security to restrict what each user can see For example, a state or district officer can be limited to viewing data only for their assigned location, while national teams retain full visibility. This enables wider data access without compromising confidentiality. 1.6 Power BI as a Data Use Enabler Power BI does not replace sound data management practices. Poor data quality will still produce poor results. What Power BI does is make good practices easier to maintain: Cleaning steps are explicit and repeatable Models enforce structure Calculations are centralized Visuals are connected to real questions When implemented correctly, Power BI shifts teams from spending time on data preparation to spending time on analysis and action. That shift is what makes Power BI matter for real-world data use. 1.7 What This Means for the Rest of This Guide This book is not about turning M&amp;E professionals into software developers. It is about helping you: Build repeatable data workflows Reduce manual reporting burden Improve consistency and trust in indicators Design dashboards that support decisions, not just reporting The next chapter introduces the Power BI ecosystem and explains how its components work together in practice. "],["from-question-to-dashboard-mindset.html", "Chapter: 2 From Question to Dashboard (Mindset) 2.1 Data Use Starts with Questions, Not Charts 2.2 Indicators Come Before Dashboards 2.3 The Concept-to-Canvas Workflow 2.4 The 5-Step Technical Workflow 2.5 The M&amp;E Mindset Shift 2.6 A Simple Mental Checklist", " Chapter: 2 From Question to Dashboard (Mindset) A common mistake beginners make is opening Power BI and immediately trying to draw charts. The tool makes it easy to drag fields onto visuals, it feels intuitive, fast, and rewarding. Unfortunately, this instinct is the primary reason public health dashboards fail. Dashboards built “visuals-first” may look impressive during a demo, but they are often fragile. They fail to answer meaningful questions, they break when next month’s data arrives, and they require complete rebuilding when a stakeholder asks for a simple change. Effective data use requires a fundamental shift in mindset. Power BI rewards structure before style. 2.1 Data Use Starts with Questions, Not Charts Power BI is not a charting tool. It is a decision-support tool. In the rush to visualize, analysts often skip the most important step: defining the purpose. Before you connect to a single data source, you must pause to ask: What decision needs to be made? (e.g., allocating mobile clinics, ordering ARV stock, hiring staff) Who needs to make that decision? (e.g., District Health Officer, M&amp;E Manager, Donor) What information would change their action? In Monitoring and Evaluation (M&amp;E) and Public Health, these questions are rarely abstract. They are practical, high-stakes, and time-bound: “Are we on track to meet the UNAIDS 95-95-95 targets in the Northern Region?” “Which facilities have a Lost-to-Follow-Up rate higher than 5% this quarter?” “Is the drop in ANC visits seasonal, or is it a service delivery failure?” Dashboards exist to answer these questions. If a visual does not support a decision, it is noise. 2.2 Indicators Come Before Dashboards In development programs, indicators are the bridge between raw data and decisions. In Excel, you might be used to creating a pivot table and calculating a percentage right there in the cell. If you need to change the definition, you edit the cell formula. In Power BI, this approach is dangerous. A useful workflow looks like this: Define the Question Define the Indicator (The Logic) Define the Data Required (The Ingredients) Build the Dashboard (The Surface) Skipping directly to dashboards reverses this logic. It forces you to build logic inside the visual, which creates “Implicit Logic.” 2.2.1 The Danger of “Implicit Logic” Implicit logic happens when you define an indicator using filters on a specific chart rather than a global formula. Case Study: The “Retention Rate” Trap Imagine you want to show the Retention Rate for HIV patients. The Visuals-First Approach: You drag a count of patients to a bar chart. You drag a filter to the side and uncheck “Transferred Out” and “Dead.” You rename the chart title to “Retention.” The Risk: Next week, a colleague copies that chart but forgets to copy the filters. Or, they add a filter for “Age &lt; 15.” Suddenly, the two charts show different numbers for the same metric. There is no single “truth”(only different views). The Indicators-First Approach: You write a DAX Measure. You explicitly define the math: Retention Rate = DIVIDE( [Active Patients], [Total Enrolled] - [Transferred Out] ) The Reward: This definition is now hard-coded into the model. Whether you put it on a map, a card, or a table, it always calculates correctly. You have created a Single Source of Truth. For the M&amp;E professional, “Viral Load Suppression” is not a chart. It is a strict definition. Once that definition is clear, Power BI can calculate it consistently across time, geography, and disaggregation. This is why modeling and calculations matter more than visuals. 2.3 The Concept-to-Canvas Workflow To implement this mindset, follow this 4-step workflow for every report you build. 1. Define the Question (The Strategic Layer) Don’t ask “What data do we have?” Ask “What do we need to know?” * Bad Start: “I have a CSV of malaria cases.” * Good Start: “We need to identify districts where malaria incidence is rising despite bed net distribution.” 2. Define the Indicator (The Logic Layer) Treat this like a laboratory protocol. It must be reproducible. In M&amp;E, this usually involves defining a Numerator and a Denominator. Indicator: Viral Load Suppression Rate. Numerator: Number of patients with VL &lt; 1000 copies/ml. Denominator: Total number of patients with a documented VL result. Nuance: Does “documented result” mean within the last 12 months? Does it include children? These rules must be written down before you build. 3. Define the Data Required (The Data Layer) Now that you know the formula, identify the ingredients. Do you need the lab_results table from the LIMS? Do you need the patient_demographics table from the EMR? Do you need to join them on PatientID? Do these tables speak the same language? (e.g., does one use “M/F” and the other “Male/Female”?) 4. Build the Dashboard (The Visual Layer) Only now, after steps 1–3, do you open the Power BI canvas. Because you have defined the indicator, you know exactly what measures to write. The visuals become simple containers for your logic. 2.4 The 5-Step Technical Workflow Once you have your plan, Power BI follows a technical workflow that mirrors good analytical practice. 2.4.1 1. Get Data (Connect) This step answers one question: Where does the data live? Data may come from Excel, DHIS2, SQL Server, ODK/KoboToolbox, or APIs. At this stage, the goal is access, not perfection. In public health, data is often fragmented across multiple systems; your first task is simply to bring it into the Power BI kitchen. 2.4.2 2. Transform (Shape) Raw data reflects how systems collect information, not how analysts use it. Common public health data issues include: “Wide” Data: Months spread across columns (Jan, Feb, Mar) instead of rows. Dirty Data: “District A” and “Dist. A” treated as different places. Missing Headers: Cryptic codes like var_001 instead of Diagnosis. In Excel, you might fix these manually every month. In Power BI, you use Power Query to record these steps. This ensures that next month, when the new data arrives, the cleaning happens automatically. 2.4.3 3. Model (The Brain of the Report) The data model is where the magic happens. It determines what questions your dashboard can answer. You define relationships between tables: Patients belong to Facilities. Facilities belong to Districts. Results belong to Time Periods. A strong model allows you to slice a single indicator (like “Positivity Rate”) by any dimension (Age, Sex, Location, Time) without writing new formulas. This is the superpower of Power BI compared to Excel. 2.4.4 4. Visualize (With Purpose) Visualization is the tip of the iceberg. It is the only part the user sees, but it relies entirely on the model beneath it. Good visuals in Public Health are functional, not decorative. They should: Answer the question: What is the HIV prevalence in a specified populations? Highlight outliers: Which facility is failing? Show trends: Is the epidemic curve flattening? Enable drill-down: Click on a province to see its districts. 2.4.5 5. Publish (Enable Use) A dashboard that lives on your desktop is useless. Publishing involves sharing the report to the Power BI Service, setting up automated data refreshes (so you don’t have to email files), and managing security (so the right people see the right data). Power BI Publish 2.5 The M&amp;E Mindset Shift This workflow requires a deliberate shift in thinking. The table below outlines how your approach must change when moving from Excel to Power BI. Feature Old Mindset (Excel) New Mindset (Power BI) Goal “I need to make a chart for the donor.” “I need to build a model that answers donor questions.” Formulas Logic is hidden in cell formulas (e.g., =C2/D2). Logic is explicit in named Measures (e.g., [New Positives] / [Tests]). Data Updates New data requires manual copy-pasting and checking. New data flows through an automated pipeline. Filtering Filters are applied to specific charts or rows. Filters propagate through relationships in the data model. Outcome Fragile &amp; One-off Robust &amp; Scalable 2.6 A Simple Mental Checklist Before building any dashboard, ask yourself: Question: Do I know what decision this supports? Definition: Can I write the formula for the indicator on a whiteboard? Data: Is the raw data accessible and consistent? Model: Will this model survive if the user asks for a new disaggregation? If the answer to any of these is no, the solution is not another chart. It is to step back and plan. What to Carry Forward This book follows this exact workflow: Questions before dashboards. Structure before style. Reuse before reinvention. The next chapter moves into the first technical step: connecting Power BI to common data sources used in M&amp;E and public health programs. "],["understanding-the-power-bi-ecosystem.html", "Chapter: 3 Understanding the Power BI Ecosystem 3.1 Power BI Desktop (The Kitchen) 3.2 Power BI Service (The Restaurant) 3.3 Power BI Mobile (The Takeout) 3.4 The Power BI Gateway (The Bridge) 3.5 How the Ecosystem Works in Practice 3.6 Common Misunderstandings to Avoid 3.7 What to Remember from This Chapter", " Chapter: 3 Understanding the Power BI Ecosystem Power BI isn’t just a single program. It is a collection of tools, each designed for a specific role in the data life cycle. Honestly, most frustrations with Power BI come from not understanding this separation. You often see analysts trying to share files directly from Desktop, stakeholders expecting to edit reports in the Service, or teams completely underestimating the importance of the Gateway. This chapter gives you a clear mental model of how the ecosystem works and how the components fit together in real-world M&amp;E and public health workflows. At a high level, the ecosystem separates: Development Distribution Consumption 3.1 Power BI Desktop (The Kitchen) Power BI Desktop is a free Windows application where the technical work happens. Primary role: Authoring and development Who uses it: Data analysts, M&amp;E officers, data managers Typical tasks: Connecting to data sources Cleaning and transforming data with Power Query Building data models and relationships Writing DAX calculations Designing report pages Think of Power BI Desktop as the Kitchen. This is where ingredients are prepared and recipes are tested. It is not designed for end users. When too many people work directly in the Desktop file, version control breaks down and consistency is lost. When you first open Power BI Desktop, you are presented with the main report canvas and common data connection options. Power BI Desktop start screen showing data connection options Note: Treat Power BI Desktop as a controlled environment. Fewer authors and stronger standards lead to more reliable dashboards. 3.2 Power BI Service (The Restaurant) The Power BI Service is the cloud-based platform accessed through a web browser. Primary role: Distribution and collaboration Who uses it: Program managers, technical leads, leadership, partners Typical tasks: Publishing reports from Desktop Scheduling data refreshes Managing users and permissions Creating dashboards from reports Sharing content securely The Service is the Restaurant. Stakeholders come here to consume data. They can filter, drill down, and interact with visuals, but they cannot change the underlying calculations or data structures. This separation protects data integrity while still encouraging exploration. Power BI Service 3.3 Power BI Mobile (The Takeout) Power BI Mobile consists of native applications for Android and iOS devices. Primary role: Quick access and field-level consumption Who uses it: Field officers, supervisors, roving program staff Typical tasks: Viewing dashboards optimized for small screens Checking trends before meetings or site visits This is the Takeout experience. In decentralised programs, mobile access allows teams to engage with data closer to the point of service delivery rather than waiting to get back to the office. 3.4 The Power BI Gateway (The Bridge) Many development and public health organisations rely on on-premise systems, including: Local SQL databases DHIS2 instances hosted within private government networks EMRs deployed at the facility or state level The Power BI Gateway acts as a secure bridge between these systems and the Power BI Service. It enables automated refresh from internal data sources. It runs inside the organisation’s network. It prevents direct exposure of databases to the internet. Note: Gateway misconfiguration is one of the most common reasons dashboards fail after deployment. Plan for this early. 3.5 How the Ecosystem Works in Practice A typical workflow looks like this: Data is connected, cleaned, and modeled in Power BI Desktop. The report is published to the Power BI Service. A Gateway refreshes data on a schedule (if the data is on-premise). Stakeholders access dashboards via the Service or Mobile app. Note Each component has a defined responsibility. Respecting these boundaries keeps systems stable and scalable. 3.6 Common Misunderstandings to Avoid Treating Power BI Desktop as a sharing tool (don’t email .pbix files). Allowing many people to independently rebuild the same report. Ignoring gateway planning until deployment. Expecting mobile apps to replace full dashboards. Understanding these limits early prevents frustration later. 3.7 What to Remember from This Chapter Power BI Desktop is for building and modeling. Power BI Service is for sharing and collaboration. Power BI Mobile supports field-level access. The Gateway enables secure, automated refresh. Once this ecosystem is clear, Power BI becomes much easier to learn and use effectively. The next chapter focuses on connecting Power BI to common data sources used in M&amp;E and public health programs. "],["connecting-to-common-data-sources.html", "Chapter: 4 Connecting to Common Data Sources 4.1 Before You Begin: The Sample Dataset Used in This Book 4.2 File-Based Data Sources 4.3 Understanding Why CSV Is Used Here 4.4 The Folder Connector (Optional but Powerful) 4.5 Database and Online Sources (Context Only) 4.6 Understanding Connection Modes 4.7 Practice Summary", " Chapter: 4 Connecting to Common Data Sources Power BI Desktop can connect to hundreds of different data sources, but most Monitoring and Evaluation and Public Health workflows rely on a small and predictable subset. The Get Data button on the Home ribbon is always the starting point. However, effective use of Power BI is less about knowing every connector and more about knowing which connector to use in a given situation. In this chapter, we will connect Power BI to the integrated sample datasets used throughout this book and build confidence before we begin cleaning and modeling the data. 4.1 Before You Begin: The Sample Dataset Used in This Book All practical exercises in this guide use a synthetic, patient-level integrated health dataset generated specifically for learning. The dataset represents routine service delivery across: Antenatal Care (ANC) HIV and ART Malaria Tuberculosis (TB) Non-Communicable Diseases (NCDs) No real patient data is used. 4.1.1 Files Included You should have the following CSV files available: dim_patient.csv dim_facility.csv dim_date.csv fact_patient_visits.csv These files are intentionally not clean. They contain common data quality issues that reflect real health information systems. We will address these issues in later chapters. For now, focus only on connecting the data successfully. 4.2 File-Based Data Sources File-based data is the most common entry point for M&amp;E professionals and is how we will begin. All sample datasets used in this book are provided as CSV files, making them easy to import and reuse. 4.2.1 Practical Exercise 4.1: Importing the Integrated Health Fact Table Objective: Connect Power BI to the main patient-level fact table. Steps: Open Power BI Desktop Click Get Data → Text/CSV Select fact_patient_visits.csv Review the data preview Click Load To import a CSV file, use the Get Data menu and select the Text/CSV option. What to Observe: The number of rows loaded Yes/No fields with inconsistent formatting Date fields that appear as text Missing or unexpected values To view the imported data, click the Table View icon on the left sidebar. Do not attempt to fix anything yet. We will address these issues in the next chapter. 4.2.2 Practical Exercise 4.2: Importing Dimension Tables Objective: Import supporting dimension tables used for analysis. Repeat the steps above for each of the following files: dim_patient.csv dim_facility.csv dim_date.csv You should now have four tables loaded into Power BI. Reflection: As you review the imported tables, consider: Which tables contain unique records? Which tables are primarily descriptive? Which table contains repeated transactional records? Which fields look suitable for relationships? These questions will become important in the modeling chapter. 4.3 Understanding Why CSV Is Used Here CSV files are widely used for data exchange in public health systems, including exports from: DHIS2 EMRs KoboToolbox and ODK Laboratory systems They are lightweight, consistent, and ideal for automation, but they often contain: Formatting inconsistencies Missing values Invalid dates Mixed data types Power BI is designed to handle these challenges when used correctly. 4.4 The Folder Connector (Optional but Powerful) In real-world reporting, data is often received periodically, such as: Monthly extracts Quarterly program reports Routine facility submissions The Folder connector allows Power BI to combine multiple files with the same structure automatically. 4.4.1 Practical Exercise 4.3: Exploring the Folder Connector (Optional) Objective: Understand how Power BI handles multiple files. Setup (Optional): Create a folder on your computer Copy fact_patient_visits.csv into it multiple times Rename the copies (for example: Jan_visits.csv, Feb_visits.csv) Steps: Click Get Data → Folder Select the folder Click Combine and Transform Reflection: Review the combined data preview Observe how Power BI applies the same steps to each file Note how this approach supports ongoing reporting We will not use this method for the main exercises, but it is important to understand. 4.5 Database and Online Sources (Context Only) As programs scale, data may be stored in: SQL databases Cloud platforms APIs SharePoint Lists Power BI supports these sources, often with the help of a gateway for secure refresh. For now, we focus on file-based data to keep learning accessible and reproducible. 4.6 Understanding Connection Modes When importing the sample datasets, Power BI uses Import mode by default. 4.6.1 Import Mode (Recommended) Data is copied into Power BI’s internal engine Performance is fast All features are available Ideal for most M&amp;E and public health analysis 4.6.2 DirectQuery Mode (Not Used Here) DirectQuery keeps data in the source system and queries it live. While useful in some scenarios, it introduces complexity and limitations that are unnecessary for this guide. Rule of thumb: If you are learning or unsure, use Import. 4.7 Practice Summary By the end of this chapter, you should have: Imported all four sample datasets Confirmed that data loads successfully Resisted the urge to clean or model prematurely At this stage, the data may look messy. That is expected. The next chapter focuses on cleaning and transforming data using Power Query, where we will systematically fix these issues and prepare the data for proper modeling and analysis. "],["power-query-basics-that-actually-matter.html", "Chapter: 5 Power Query Basics That Actually Matter 5.1 Why Power Query Matters in Public Health Data 5.2 What Power Query Is (and Is Not) 5.3 Understanding the Power Query Interface 5.4 Why Power Query Feels Like “Magic” 5.5 Power Query Thinking vs Excel Thinking 5.6 The Principle of Repeatable Cleaning 5.7 Query-Level vs Column-Level Cleaning 5.8 Working With the Sample Dataset 5.9 Understanding the Role of Each Table in Cleaning 5.10 Core Data Cleaning Patterns for Messy Health Data 5.11 Reading Power Query Steps as Logic 5.12 Why the Order of Steps Matters 5.13 Data Quality Rules Reference 5.14 What Not to Do in Power Query 5.15 A Simple Exit Checklist 5.16 What This Enables Next 5.17 Stop Point: When to Leave Power Query", " Chapter: 5 Power Query Basics That Actually Matter If Power BI is a house, Power Query is the foundation. If the foundation is weak, everything built on top of it will eventually fail. In public health and development programs, most reporting problems are not caused by poor visuals. They are caused by inconsistent, fragile, or undocumented data preparation. Power Query exists to make data cleaning explicit, repeatable, and defensible. This chapter focuses on the parts of Power Query that actually matter for reliable data use. 5.1 Why Power Query Matters in Public Health Data Health data is complex by nature. It comes from multiple systems, is collected by different actors, and often changes definitions over time. Missing values, placeholder codes, and inconsistent formats are common. When these issues are handled manually in Excel, the logic is hidden. Hidden logic cannot be reviewed, reproduced, or trusted. Power Query forces transparency. Every transformation is recorded, ordered, and replayed exactly the same way every time data is refreshed. This is not convenience. It is governance. 5.2 What Power Query Is (and Is Not) Power Query is a data transformation engine. When you click Transform Data in Power BI Desktop, you open the Power Query Editor, a dedicated environment for preparing data before analysis. Power Query is: - Deterministic - Repeatable - Explicit Power Query is not: - A visualization tool - A place to calculate indicators - A replacement for data modeling Its purpose is singular: turn raw, messy data into structured analytical inputs. 5.3 Understanding the Power Query Interface The Power Query Editor has three areas that matter conceptually. 5.3.1 The Ribbon The ribbon contains buttons for common transformations such as: - Split Column - Group By - Replace Values - Change Data Type These buttons do not directly clean data. They generate steps. The step matters more than the button. 5.3.2 The Queries Pane Each item in the Queries pane represents a dataset, referred to as a query. In this book, these include: - fact_patient_visits - dim_patient - dim_facility - dim_date At this stage: - Do not join queries - Do not calculate indicators - Do not optimize visuals Think of each query as an ingredient being prepared independently. 5.3.3 The Applied Steps Pane This is the most important part of Power Query. Every transformation is recorded as a step: - Source - Navigation - Changed Type - Removed Columns - Replaced Values Note: Together, these steps form a data preparation contract: This is exactly how raw data becomes analysis-ready. Deleting or reordering steps changes that contract. 5.4 Why Power Query Feels Like “Magic” In Excel, data cleaning is manual and repetitive. If you clean this month’s file, you must repeat the same work next month. In Power Query, you are not cleaning data once. You are recording logic. When new data arrives and you click Refresh, Power Query replays every applied step automatically. The same rules. The same order. The same results. This is the difference between one-off reporting and sustainable monitoring. 5.5 Power Query Thinking vs Excel Thinking Excel encourages manual correction. Power Query requires logical definition. In Excel: - You fix a cell - The logic lives in your head In Power Query: - You define a rule - The logic lives in the steps If a fix cannot be described as a rule, it does not belong in Power Query. 5.6 The Principle of Repeatable Cleaning In Monitoring and Evaluation work, numbers must be defensible. If someone asks, “How did you arrive at this figure?”, the answer should be a documented sequence of steps, not personal judgment. Before applying any transformation, ask: - Will this still work if new rows are added? - Will this break if values change? - Can another analyst understand this step? If the answer is no, rethink the approach. 5.7 Query-Level vs Column-Level Cleaning Not all cleaning decisions are equal. Some issues affect the entire dataset, while others affect specific columns. Query-level cleaning applies to the structure of the dataset Examples include: Removing empty rows Filtering invalid records Renaming queries Column-level cleaning applies to individual fields Examples include: Standardizing Yes/No values Converting data types Replacing sentinel values A good rule of thumb: - Structural problems belong at the query level while Meaning problems belong at the column level. 5.8 Working With the Sample Dataset This chapter focuses primarily on the fact_patient_visits table. This dataset intentionally includes: - Inconsistent Yes/No values - Dates stored as text - Sentinel values such as 999 - Missing ART start dates and regimens These are not errors. They reflect real system behaviour and are included to support learning. 5.9 Understanding the Role of Each Table in Cleaning Not all tables require the same level of cleaning, and not all issues should be handled in the same place. In this project, the tables serve different purposes: fact_patient_visits Contains transactional records and is the primary source of complexity. Most cleaning effort happens here. dim_patient Contains relatively stable demographic attributes. Cleaning focuses on consistency and validity. dim_facility Mostly descriptive. Cleaning focuses on standardization rather than logic. dim_date Should be clean by design. Any issues here usually indicate upstream problems. Understanding the role of each table helps you decide what to clean, where to clean it, and what to defer. 5.10 Core Data Cleaning Patterns for Messy Health Data 5.10.1 Setting Correct Data Types This is the most common source of silent errors. Data types determine what can be calculated, aggregated, and filtered correctly. Common issues include: - Dates stored as text - Numeric values mixed with symbols - Boolean values recorded inconsistently Always review the automatically generated Changed Type step. Do not assume Power BI guessed correctly. 5.10.2 Exercise 5.1: Data Type Audit Objective: Identify and correct incorrect data types. Steps: 1. Open the Power Query Editor 2. Select the fact_patient_visits query 3. Review the data type icon beside each column 4. Identify at least three columns with incorrect data types 5. Explicitly set the correct data type Reflection: - Which values became null after correction? - What does this reveal about source data quality? 5.10.3 Standardizing Categorical Values Health datasets often encode the same concept in multiple ways: - Yes, YES, Y, 1 - No, NO, N, 0 These differences matter in filters and calculations. The goal is one representation per concept. 5.10.4 Exercise 5.2: Standardizing Yes and No Fields Objective: Normalize categorical values. Steps: 1. Choose a Yes/No column (for example, hiv_tested) 2. List all distinct values 3. Use Replace Values to standardize to Yes and No Reflection: - How many representations existed? - What errors would occur if these were left uncleaned? 5.10.5 Handling Missing and Sentinel Values Missing data is not the same as zero. Common placeholders include: - 999 - -1 - Unknown - Not Recorded Leaving these values untreated will distort averages and rates. Convert placeholders to null. Power BI ignores nulls in calculations. 5.10.6 Exercise 5.3: Replacing Sentinel Values Objective: Prevent placeholder values from distorting analysis. Steps: 1. Identify numeric columns with sentinel values 2. Replace sentinel values with null 3. Confirm the column data type remains numeric Reflection: - Why is null safer than a numeric placeholder? - How would this affect indicator calculations? 5.10.7 Cleaning ART-Related Fields Treatment data often contains logical inconsistencies. Examples include: - ART regimens without start dates - Start dates present when ART is marked as No These issues must be handled consistently. 5.10.8 Exercise 5.4: ART Logic Consistency Objective: Apply logical rules to treatment data. Steps: 1. Identify records where art_started = Yes but art_start_date is missing 2. Identify records where art_started = No but art_regimen is populated 3. Define a consistent rule 4. Apply the rule using Power Query logic Reflection: - What assumptions are safe at the cleaning stage? - What should be deferred to analysis? 5.10.9 Unpivoting for Time and Indicator Analysis Wide tables are human-readable. Tall tables are machine-readable. Power BI works best with tall tables where: - Time is a variable - Indicators are values, not column names 5.10.10 Exercise 5.5: Unpivoting Data Objective: Convert wide data into analysis-ready format. Steps: 1. Identify identifier columns 2. Select those columns 3. Right-click and choose Unpivot Other Columns 4. Rename resulting columns appropriately Reflection: - Why does this structure support trend analysis? - How does it simplify dashboard design? 5.11 Reading Power Query Steps as Logic Every Power Query step is written in M language. You do not need to master M at this stage, but you should: - Read step names carefully - Rename steps to reflect intent - Avoid leaving steps as generic defaults Note: Clear steps build trust. 5.12 Why the Order of Steps Matters Power Query steps are executed from top to bottom. This means: Changing data types before replacing values may introduce errors Removing columns too early may break later steps Reordering steps can silently change results For example: Replacing 999 with null should happen before setting numeric data types Splitting columns should happen before renaming them Note: When debugging Power Query issues, always review step order first. 5.12.1 Exercise 5.6: Renaming Applied Steps Objective: Improve transparency and maintainability. Steps: 1. Review the Applied Steps pane 2. Rename steps such as Changed Type 3. Use descriptive names Set Correct Data Types Standardize Yes No Values Replace Sentinel Values Reflection: Could another analyst understand this logic? Would this hold up in an audit or handover? 5.13 Data Quality Rules Reference The table below summarizes data quality rules applied throughout this book. Domain Data Element Common Issue Rule Applied Rationale Demographics Age Text instead of numeric Convert to numeric, invalid to null Prevent calculation errors Visits Visit Date Stored as text Convert to Date Enable time analysis ANC ANC Visit Inconsistent categories Standardize values Reliable filtering HIV HIV Tested Mixed encodings Normalize categories Accurate rates ART ART Start Date Missing when ART = Yes Flag as incomplete Avoid false counts ART ART Regimen Inconsistent labels Standardize text Regimen analysis Malaria Test Result Placeholder values Replace with null Correct positivity TB TB Screened Missing values Treat conservatively Avoid overestimation NCD Screening Result Mixed formats Normalize categories Comparable indicators These rules support clean analysis, not indicator definitions. 5.14 What Not to Do in Power Query At this stage, do not: - Calculate indicators - Create ratios or percentages - Join fact and dimension tables - Apply user-specific logic Note: Power Query prepares data. Meaning is defined later. 5.15 A Simple Exit Checklist Before leaving Power Query, ask: - Are data types correct? - Are categories consistent? - Are missing values handled properly? - Are steps readable and ordered? If yes, you are ready to model. 5.16 What This Enables Next By the end of this chapter, you should have: - Clean, structured tables - Documented transformations - Confidence in your inputs In the next chapter, we will build a data model that connects these tables using relationships and prepares them for indicator calculation. Notes: Power Query gives you control over data. Modeling gives you control over meaning. Good dashboards start with good visuals.Trusted dashboards start with clean data. 5.17 Stop Point: When to Leave Power Query You should exit Power Query when: - Data types are correct - Categories are standardized - Missing values are handled consistently - Structural issues are resolved You should not remain in Power Query to: - Interpret indicators - Apply donor definitions - Create performance metrics At this point, the data is clean, not meaningful. Meaning comes next. "],["the-star-schema-the-backbone-of-analytical-models.html", "Chapter: 6 The Star Schema: The Backbone of Analytical Models 6.1 What is a Star Schema ? 6.2 The Central Idea: Events Surrounded by Context 6.3 Fact Tables: Recording Reality 6.4 Dimension Tables: Stable Descriptions 6.5 Why Facts Should Not Contain Descriptions 6.6 The Role of Keys: Connecting Meaning Without Carrying It 6.7 Relationships: How Meaning Flows 6.8 Filter Direction: Why It Must Be One-Way 6.9 Why Dimensions Should Not Connect to Each Other 6.10 Time as a First-Class Dimension 6.11 Visualizing the Star (Mental Model) 6.12 Hands-On: Building the Star Schema in Power BI 6.13 Common Modeling Errors to Watch For 6.14 A Simple Rule to Remember 6.15 Reflection: Why This Step Matters 6.16 Stop Point: Do Not Move Forward Yet 6.17 What Comes Next", " Chapter: 6 The Star Schema: The Backbone of Analytical Models Reliable analytics do not start with visuals or calculations. They start with structure. In Power BI and in all analytical systems, the structure that enables clarity, consistency, and trust is the star schema. The star schema is not a Power BI feature.It is a data modeling pattern that predates modern BI tools and remains the foundation of professional analytics. Once you understand it, most modeling decisions become obvious. 6.1 What is a Star Schema ? A star schema organizes data around a single central table of events, surrounded by descriptive tables. The fact table sits at the center Dimension tables radiate outward Relationships form a star-like shape Each table has a single responsibility. The star schema is: A way of thinking A way of separating meaning A way of protecting definitions It is not: A Power BI layout trick A performance hack A cosmetic design choice 6.2 The Central Idea: Events Surrounded by Context At the core of the star schema is a simple question: What actually happened? The answer lives in the fact table. Everything else exists to describe that answer. 6.3 Fact Tables: Recording Reality A fact table records events as they occurred. Each row answers the question: “Something happened. What was it?” Fact tables typically contain: Identifiers (who, where, when) Measurements (counts, flags, results) They do not explain context in detail. 6.3.1 Example: Health Service Delivery In this book: fact_patient_visits records service delivery events One row equals one interaction between a patient and the health system This table grows continuously over time and represents measurable reality. 6.4 Dimension Tables: Stable Descriptions A dimension table provides descriptive context for events. Each row answers the question: “What do we know about this entity?” Dimension tables: Change slowly Contain descriptive attributes Are reused across multiple analyses Examples: One row per patient One row per facility One row per calendar date Dimensions do not record activity. They provide meaning. 6.5 Why Facts Should Not Contain Descriptions A common beginner instinct is to “simplify” analysis by copying descriptive fields into the fact table. For example: Facility name stored on every visit row District repeated thousands of times Patient age recalculated inconsistently Month and year embedded as text This creates three problems: Redundancy : The same information appears repeatedly. Inconsistency : Descriptions drift over time. Fragility : Small changes require rebuilding reports. In a star schema: Fact tables contain keys and measurements Dimension tables contain descriptions This separation protects historical meaning. 6.6 The Role of Keys: Connecting Meaning Without Carrying It Relationships exist because tables share keys. A key: Uniquely identifies a record Is stable over time Has no analytical meaning itself Good keys: Patient IDs Facility IDs Date IDs Bad keys: Names Labels Descriptions Keys exist to connect meaning, not to store it. 6.7 Relationships: How Meaning Flows Relationships tell Power BI: Which tables are connected How filters propagate Which tables control context Without relationships, tables are isolated files. With correct relationships, the model behaves predictably. One-to-Many: The Default Relationship In a star schema, relationships are almost always one-to-many. Examples: One patient → many visits One facility → many visits One date → many visits In Power BI terms: Dimension table = one Fact table = many This pattern mirrors reality and supports reliable aggregation. 6.8 Filter Direction: Why It Must Be One-Way Relationships are directional. In a well-designed star schema: Filters flow from dimension → fact Not from fact → dimension This reflects real-world logic: Selecting a district limits visits Selecting a patient limits events Selecting a date limits outcomes Note: Allowing filters to flow both ways introduces ambiguity and should be avoided unless there is a very specific, justified reason. 6.9 Why Dimensions Should Not Connect to Each Other Another common mistake is linking dimension tables directly. For example: dim_patient linked to dim_facility dim_facility linked to dim_date This creates: Multiple filter paths Ambiguous context Unpredictable results In a star schema: Dimensions connect only to the fact table The fact table is the bridge between all context If two dimensions need to interact, they do so through events. 6.10 Time as a First-Class Dimension Time is not just a filter. A date has structure: Day Month Quarter Year Reporting period Fiscal calendar Embedding raw dates in fact tables limits analysis. A dedicated date dimension enables: Consistent aggregation Year-over-year comparison Alignment with reporting calendars This is why professional models never rely on raw date fields alone. 6.11 Visualizing the Star (Mental Model) Think of the model this way: The fact table is the question Dimensions are the ways to slice the answer If you remove the fact table, nothing is left to analyze. If you remove a dimension, analysis still works but just with less context. This is how you know the structure is correct. 6.11.1 Star Schema Diagram (Conceptual) 6.12 Hands-On: Building the Star Schema in Power BI This section translates the concepts you have learned into practical modeling steps. Do not rush. Every action here reinforces the mental model you have just developed. Step 1: Switch to Model View After completing data cleaning in Power Query: Close the Power Query Editor In Power BI Desktop, select the Model View icon from the left sidebar You should see all imported tables displayed separately. At this stage, Power BI may show suggested relationships. Do not accept or rely on them yet. Step 2: Classify Tables Before Creating Relationships Before dragging any fields, pause and classify each table using the concepts from this chapter. Using the datasets in this book: Fact table fact_patient_visits Dimension tables dim_patient dim_facility dim_date Ask yourself: Which table records events? Which tables describe context? If this is unclear, return to the earlier sections before proceeding. Step 3: Identify Relationship Keys Each relationship requires a key that uniquely identifies a record in a dimension table. Confirm the following keys exist: dim_patient[patient_id] dim_facility[facility_id] dim_date[date_id] In the fact table, these same fields appear repeatedly as references. Reminder: Keys connect meaning. They do not describe it. Step 4: Create Dimension-to-Fact Relationships Create relationships manually to ensure correctness. Example: Patient to Visits Drag patient_id from dim_patient Drop it onto patient_id in fact_patient_visits In the relationship dialog, confirm (see image below): - Cardinality: One-to-many - Cross-filter direction: Single - Active relationship: Yes Repeat the same process for: facility_id → dim_facility -date_id → dim_date Step 5: Enforce the Star Shape Visually Arrange tables in the Model View so that: fact_patient_visits sits at the center Dimension tables surround it No dimension table connects directly to another dimension This visual layout is not cosmetic. It reinforces correct analytical thinking and simplifies troubleshooting. Step 6: Validate Filter Flow Before building visuals or calculations, test whether the model behaves as expected. Switch to Report View Add a simple table visual Add: Facility Name (from dim_facility) Count of rows from fact_patient_visits Now apply filters: Select a district Select a reporting period If counts respond logically, filter flow is working correctly. If not, return to Model View and review relationships. Step 7: Hide Technical Fields (Optional but Recommended) Keys are essential for modeling but confusing for report users. To hide them: Switch to Data View Right-click technical fields such as: patient_id facility_id date_id Select Hide in report view This prevents accidental misuse during visualization. 6.13 Common Modeling Errors to Watch For Most Power BI models do not fail loudly. They fail quietly. Numbers still appear, Charts still render, Filters still move but the logic underneath becomes unstable. The following mistakes are responsible for the majority of “almost correct” dashboards in public health and M&amp;E. 1. Many-to-Many Relationships Created Unintentionally This is one of the most dangerous modeling errors because Power BI often allows it without warning. Why it happens Many-to-many relationships usually appear when: A dimension table contains duplicate keys A fact table is linked to another fact table Text fields are used as join keys Aggregated data is mixed with transaction-level data In health data, this commonly happens when: Facility names are duplicated across systems Patient identifiers are inconsistent Monthly summaries are joined directly to line lists Why it is dangerous Many-to-many relationships: Inflate counts Distort totals Produce inconsistent results depending on filters Make DAX calculations unpredictable The same indicator may return different values depending on where it is used. How to think your way out If a relationship is many-to-many, pause and ask: “What is the event?” “What is the description?” “Should these tables even be directly connected?” In most cases, the solution is: Introduce or fix a dimension table Clean keys Revisit granularity 2. Bi-Directional Filters Applied Without Justification Bi-directional filtering allows context to flow in both directions between tables. It feels powerful. It is rarely necessary. Why it happens Users often enable bi-directional filters because: A visual “doesn’t work” A slicer does not behave as expected Power BI suggests it automatically Instead of fixing structure, filters are allowed to flow both ways. Why it is dangerous Bi-directional filters: Create hidden filter paths Introduce ambiguity Make results dependent on visual layout Break assumptions in DAX measures The model becomes difficult to reason about. How to think your way out In a star schema: Dimensions define context Facts respond to context If you feel the need for bi-directional filters, it often means: - The model is not truly star-shaped - Tables are playing multiple roles - A bridge table is missing Fix structure before changing filter direction. 3. Descriptive Fields Used as Relationship Keys Using names, labels, or descriptions as join fields is a common beginner shortcut. It almost always leads to long-term problems. Why it happens Descriptive fields are: Human-readable Easy to recognize Available in every dataset So they feel convenient. Why it is dangerous Descriptions: Change over time Are not guaranteed to be unique May be spelled inconsistently May include formatting differences When a description changes, historical analysis breaks. How to think your way out Relationships should be built on: Stable identifiers Surrogate keys Fields with no business meaning Descriptions belong in dimension tables. Keys exist only to connect. 4. Dimension Tables Linked Directly to Each Other Linking dimension tables may feel logical, but it breaks analytical clarity. Why it happens This usually occurs when: Users try to “help” Power BI navigate context Dimensions share a common attribute The fact table feels unnecessary Why it is dangerous When dimensions link directly: Filter paths multiply Context becomes ambiguous Results depend on evaluation order Measures become fragile Power BI can no longer determine a single, authoritative path. How to think your way out In a star schema: Dimensions never describe each other They describe events If two dimensions need to interact, ask: “Where did this interaction occur?” “What event connects them?” The answer almost always points back to the fact table. 6.14 A Simple Rule to Remember If your model: Is hard to explain Requires frequent filter overrides Produces inconsistent totals Breaks when visuals change The problem is rarely DAX. It is almost always the model. Strong models make analytics boring. Weak models make analytics confusing. This chapter exists to help you build the former. 6.15 Reflection: Why This Step Matters At this point, you have not created a single indicator or chart. Yet you have already: Defined how data flows Controlled how context is applied Protected future calculations from ambiguity This is the difference between building dashboards and building analytical systems. 6.16 Stop Point: Do Not Move Forward Yet Before proceeding to calculations, confirm: There is exactly one central fact table All dimensions connect only to the fact table All relationships are one-to-many Filter direction flows from dimension to fact If any of these conditions are not met, fix them now. 6.17 What Comes Next With a proper star schema in place, Power BI can now: Understand context Apply filters consistently Support reusable indicator definitions The next chapter introduces DAX measures, where numerators and denominators are defined once and trusted everywhere. A strong model makes DAX simpler. A weak model makes DAX fragile. "],["dax-without-fear.html", "Chapter: 7 DAX Without Fear 7.1 What DAX Really Is 7.2 Measures vs Calculated Columns 7.3 Thinking in Indicators, Not Formulas 7.4 Context: The Core Idea Behind DAX 7.5 Core DAX Patterns You Will Reuse 7.6 Variables: Making DAX Easier to Read and Trust 7.7 Common DAX Mistakes (And Why They Happen) 7.8 What to Carry Forward", " Chapter: 7 DAX Without Fear For many Power BI users, DAX is where confidence breaks. People describe DAX as too complex, too mathematical, easy to get wrong, or meant only for “advanced users.” In reality, DAX is none of these things. DAX is simply the language Power BI uses to answer questions precisely. If you already work in Monitoring and Evaluation or Public Health, you already think in DAX terms. You define indicators, specify eligibility criteria, apply reporting rules, and interpret numbers in context. DAX simply formalizes that thinking into code. 7.1 What DAX Really Is DAX stands for Data Analysis Expressions. At its core, DAX is a way to: Create reusable calculations (Indicators). Define relationships between tables. Express logic clearly. Control how numbers respond to filters. Ensure consistency across reports. DAX is not: A data cleaning tool (That’s Power Query). A scripting language like R or Python. A substitute for proper modeling. Important Principle: DAX works best on top of a well-structured star schema. It cannot compensate for poor data modeling. If your DAX feels overly complicated, check your model first. 7.2 Measures vs Calculated Columns (The Most Important Concept to Understand) This distinction appears in almost every Power BI interview, and misunderstanding it leads to slow, fragile reports. Calculated Columns and Measures are both ways to create new data in Power BI, but they serve different purposes. Understanding when to use each is crucial for building efficient and reliable models. 7.2.1 i. Calculated Columns A calculated column is a new column added physically to a table. How it works: Calculated row by row. When it runs: Computed only during data refresh. Storage: Stored in the model and consumes memory. Unlike measures, calculated columns increase the file size of your Power BI model. A calculated column answers the question: “What is true about this specific row?” Common M&amp;E use cases include: Grouping age bands: dax Age Group = IF ( 'Patients'[Age] &lt; 5, \"Under 5\", \"5 and Above\" ) Creating categorical flags (e.g., “Lost to Follow-up”). Creating display-friendly labels by combining fields. Takeaway: Calculated columns are useful for classification, grouping, and slicing, not for final indicators. 7.2.2 ii. Measures A measure is a dynamic calculation formula. How it works: Aggregates data based on filters. When it runs: Evaluated at query time (whenever a user clicks a visual or changes a slicer). Storage: Not stored as physical data. It is just saved logic. A measure answers the question: “What is the result right now, given the current filters?” Common M&amp;E use cases include: Total patient visits. Number of patients tested. Coverage rates (percentages). Positivity rates. In professional models, your final indicators are almost always measures. Rule of Thumb: * If you want to put it on an Axis or Slicer (to define categories), use a Column. * If you want to put it in the Values area (to see a number), use a Measure. 7.3 Thinking in Indicators, Not Formulas Many beginners ask: “What formula should I write?” A better question is: “What exactly am I trying to measure?” In Monitoring and Evaluation, indicators are defined long before software tools are opened. DAX simply encodes those definitions. An indicator usually consists of: A population of interest. Inclusion and exclusion rules. A numerator. A denominator. A reporting context (e.g., “Annual”). DAX allows you to express this logic once and reuse it everywhere. 7.4 Context: The Core Idea Behind DAX Most confusion around DAX comes from misunderstanding “Context.” Context simply answers one question: “Which rows are visible right now?” Context is created by: * Slicers on the page. * Visual or page-level filters. * The specific row or column in a chart or matrix. * Relationships flowing between tables in the data model. DAX does not invent numbers. It evaluates expressions based on the rows that are currently visible in the context. 7.4.1 The Simplest Measure You Can Write If you have a line list of patient visits, the simplest measure is counting them. Total Visits = COUNTROWS ( fact_patient_visits ) This measure: Counts rows in the fact table Automatically respects filters If you filter by: Facility → counts visits for that facility Date → counts visits for that period District → counts visits for that district No additional logic is required. This is DAX working as intended. 7.5 Core DAX Patterns You Will Reuse You do not need to learn the entire DAX language. Most public health dashboards rely on a small set of reusable patterns. Pattern 1: Explicit Aggregation Always write explicit measures instead of relying on Power BI’s default “drag and drop” summarization. Explicit measures are clear, reusable, and auditable. If your data has a column for quantities (e.g., commodities distributed), use SUM: Total Commodities = SUM ( fact_distribution[quantity] ) If your data is a line list of events (e.g., patient visits), use COUNTROWS: Total Visits = COUNTROWS ( fact_patient_visits ) Explicit measures are: Clear Reusable Auditable Avoid implicit measures like this: Total Visits = fact_patient_visits[visit_count] Implicit measures: Are hard to read Cannot be reused Lead to inconsistent results Pattern 2: Filtered Calculations with CALCULATE CALCULATE is the most powerful function in DAX. It modifies the context. It answers the question: “Calculate this number, BUT apply these specific rules first.” Example: Counting only Malaria-positive cases tested via RDT. Malaria Positive Cases RDT = CALCULATE ( [Total Visits], // The base measure &#39;fact_patient_visits&#39;[test_type] = &quot;Malaria RDT&quot;, // Rule 1 &#39;fact_patient_visits&#39;[test_result] = &quot;Positive&quot; // Rule 2 ) This measure respects existing slicers on the page (like Date or District) but adds the strict conditions that the test must be RDT and the result must be Positive. It will produce consistent results across visuals Note: CALCULATE applies your specific hard-coded rules on top of the current context. It ensures your indicator definition is always applied, regardless of what other slicers the user touches. Pattern 3: Safe Ratios with DIVIDE Never divide indicators using / symbol. Division by zero is common in health data (e.g., a facility that did no testing last month). Using / will break your visuals with errors. Always use DIVIDE. It handles zeros gracefully. Positivity Rate = DIVIDE ([Malaria Positive Cases RDT],// Numerator [Total Tested], // Denominator 0 // Alternate result if denominator is 0 ) This ensures: No errors Stable visuals Predictable output Pattern 4: Time Intelligence Time-based comparison is central to monitoring. These calculations work best when you have a dedicated Date Dimension connected in your model. Example: Calculating visits in the previous month for comparison. Visits Last Month = CALCULATE ( [Total Visits], DATEADD ( dim_date[date], -1, MONTH ) ) Month-on-month growth: Visits MoM Growth = DIVIDE ( [Total Visits] - [Visits Last Month], [Visits Last Month], 0 ) 7.6 Variables: Making DAX Easier to Read and Trust As your logic grows, readability matters. Variables (VAR) allow you to break logic into steps, name those steps clearly, and simplify debugging. They make formulas look like indicator definitions. Instead of writing one giant ratio formula, break it down: Positivity Rate = VAR Numerator = [Malaria Positive Cases] VAR Denominator = [Total Tested] RETURN DIVIDE( Numerator, Denominator, 0 ) Variables do not change results. They change clarity. They make complex formulas easier to read by letting you label the steps, like clearly defining your numerator and denominator before dividing 7.7 Common DAX Mistakes (And Why They Happen) Most DAX problems are not syntax errors.They are “thinking” errors. Common causes include: Using DAX to compensate for weak models Overusing calculated columns Removing filters unnecessarily Copying and pasting formulas from the internet without understanding the context they were written for. When DAX feels difficult, stop and ask: What is the event I am counting? What filters apply naturally? What filters am I adding deliberately? Am I defining logic or patching structure? Here is a Simple DAX Checklist Before writing any measure, ask: What is the exact indicator definition in plain English? Which table contains the events I am counting? Which filters should apply automatically (from slicers)? Which hard-coded filters do I need to add using CALCULATE? Am I defining a ratio? If so, use DIVIDE. If you can answer these questions, the DAX will be straightforward. 7.8 What to Carry Forward DAX is not something to fear. It is the language of explicit definitions. When used correctly, indicators remain consistent, numbers are trusted, and dashboards become stable decision tools The next chapter focuses on designing visuals that respect indicators, ensuring that strong logic is communicated clearly and responsibly. "],["designing-dashboards-people-actually-use.html", "Chapter: 8 Designing Dashboards People Actually Use 8.1 The 5-Second Rule 8.2 Layout Strategy: The Z-Pattern 8.3 Choosing the Right Visual (The Most Important Skill) 8.4 Why Tables Still Matter 8.5 Avoiding Common Visualization Mistakes 8.6 Interaction Should Support Thinking 8.7 A Simple Visual Selection Checklist 8.8 Creating a Dedicated Measures Table (Strongly Recommended) 8.9 Bonus: Measures Used in This Chapter 8.10 Hands-On Practice: Choosing Visuals Deliberately 8.11 Avoiding Common Visualization Mistakes 8.12 What to Carry Forward", " Chapter: 8 Designing Dashboards People Actually Use A dashboard is not an art project. It is a decision-support tool. In Monitoring and Evaluation and Public Health, dashboards exist to answer questions, guide action, and surface risk. A visually impressive dashboard that does not support decisions has failed its purpose. This chapter focuses on choosing the right visual for the question being asked, because the wrong visual can mislead even when the data and DAX are correct. 8.1 The 5-Second Rule When a stakeholder opens a dashboard, they subconsciously ask one question: “Are we on track?” If they cannot begin to answer that question within five seconds, the dashboard is too complex. This does not mean removing detail. It means prioritizing signal over noise. The first screen should communicate status. Exploration can come later. Start With the Question, Not the Visual Before selecting any visual from the visualization pane, pause and ask: What decision is this meant to support? What comparison matters most? What change should the user notice? Different questions require different visual structures. There is no “best” visual in isolation. 8.2 Layout Strategy: The Z-Pattern Most people scan screens in a loose “Z” pattern, starting at the top-left and moving across and downward. A practical dashboard layout follows this pattern deliberately. Top Left: Status Indicators (KPIs) Use Card Visuals or Multi-Row Cards. High-level numbers that summarize performance (e.g., Total Tested, Treatment Rate). These answer “Are we on track?” immediately. Top Right: Global Filters Use Slicers for Time Period, Geography, Partner, or Donor. Placing them here allows users to frame the question before interpreting the numbers. Middle Section: Trends and Comparisons This is where the explanation happens. Trends over time (Line Charts) and comparisons across groups (Bar Charts) belong here. Bottom Section: Detail and Evidence Use Matrix or Table visuals. This is for users who want to inspect underlying data or export figures for their own reports. A good layout reduces cognitive effort. Users should not have to “hunt” for meaning. Dashboard Layout Strategy: The Z-Pattern 8.3 Choosing the Right Visual (The Most Important Skill) Choosing the wrong visual does more harm than having no dashboard at all. Below are decision-driven guidelines, not aesthetic preferences. 8.3.1 Visuals for Time-Based Questions Use when the question is: “How is performance changing over time?” Best choice: Line Chart Why: Time is continuous. Direction matters. Trends (up/down) are easier to detect with a line than with bars. Good examples: Monthly service uptake, Quarterly target achievement, Year-over-year comparison. Avoid: Column charts for long time series (it looks like a barcode); Tables for trend interpretation. Tip: If the X-axis is time, your first instinct should always be a Line Chart. 8.3.2 Visuals for Categorical Comparison Use when the question is: “Which category is higher or lower?” Best choice: Bar Chart (Horizontal preferred) Why: Length is easier for the human eye to compare than area (pie charts) or angles. Labels are easier to read horizontally, especially long names like Districts or Facilities. Good examples: Performance by District, Coverage by Facility, Uptake by Age Group. Avoid: Pie charts (hard to compare slices); Stacked bars (if totals differ significantly). Tip: Always sort your bar charts. An unsorted chart is just a random list. A sorted chart is a leaderboard. 8.3.3 Visuals for Ranking and Priority Setting Use when the question is: “Who is performing best or worst?” Best choice: Sorted Bar Chart Enhancements: Sort Descending (Highest to Lowest) to show top performers, or Ascending to identify facilities needing support. This supports: Resource allocation, targeted follow-up, and accountability discussions. 8.3.4 Visuals for Composition (Parts of a Whole) Use when the question is: “What makes up this total?” Best choices: Stacked Bar Chart or 100% Stacked Bar Use Pie Charts ONLY when: There are 2 or 3 categories (e.g., Male/Female) and differences are obvious. Avoid Pie Charts when: There are many categories (e.g., 10 Districts) or values are close (49% vs 51%). Rule of Thumb: If users have to argue about which slice is bigger, the visual is wrong. 8.3.5 Visuals for Geographic Patterns Use when the question is: “Where is performance high or low?” Best choice: Map (Used carefully) Maps are powerful but dangerous. Use when: Geography itself is the message (e.g., identifying a cluster of outbreaks). Avoid when: Exact comparison is required. It is hard to compare the size of a bubble in the North vs a bubble in the South. Always pair maps with: A bar chart or a table for precise comparison. 8.4 Why Tables Still Matter Tables are not a failure of design. They are essential when: Exact numbers matter (e.g., financial reporting or drug stock levels). Data needs to be exported. Users want to verify calculations. Power BI Tip: Use the Matrix visual instead of the standard Table visual. The Matrix acts like an Excel Pivot Table, allowing users to drill down rows (e.g., click “Region” to expand “Districts”) and aggregate columns. — 8.5 Avoiding Common Visualization Mistakes Watch for these warning signs: Too many visuals: If it doesn’t fit on one screen, it belongs on a new page. Traffic Light Abuse: Don’t color everything Red/Green. It is overwhelming. Use color only to highlight exceptions (e.g., red for “Below 50% Target”). Pie Charts for Comparison: Never use a pie chart to compare 15 districts. KPIs without Context: A number saying “5,000 Tested” means nothing. Is that good? Bad? Better than last month? Always provide context (e.g., “% of Target” or “vs Last Month”). 8.6 Interaction Should Support Thinking Interactivity is Power BI’s superpower, but only when intentional. Cross-Highlighting: Clicking a “Male” bar should filter the rest of the page to show Male data. Drill-Down: Allow users to move from Summary to Detail (e.g., Year &gt; Quarter &gt; Month). Tooltips: Use hover-over tooltips to provide extra detail without cluttering the screen. Technical Tip: If clicking one chart makes another chart look confusing, use the “Edit Interactions” button in the Format ribbon to turn off the interaction between those specific visuals. 8.7 A Simple Visual Selection Checklist Before finalizing any visual, ask: What question does this visual answer? Is this the simplest visual that answers it? Can the message be understood in a few seconds? Would a table or bar chart be clearer? If unsure, choose clarity over creativity. Let’s digress for a moment… 8.8 Creating a Dedicated Measures Table (Strongly Recommended) As dashboards grow, measures multiply quickly. Professional Power BI models store all calculations in a single Measures table. This table: Contains no data rows Has no relationships Exists only to organize logic This pattern improves clarity, maintainability, and trust in your model. 8.8.1 Practical: Creating the Measures Table Go to the Modeling tab in Power BI Desktop Click New Table Enter the following DAX expression: Measure = DATATABLE ( &quot;Placeholder&quot;, STRING, { { &quot;Do not delete&quot; } } ) Press Enter Rename the table to “Indicators” Create your first measure in this table: Total Tested = SUM ( fact_patient_visits[Number_Tested] ) Repeat for all subsequent measures, ensuring they are created in the Indicators table. Hide the “Placeholder” column from report view to avoid accidental use by right-clicking on the placeholder column and select Hide in report view. Your model now has a dedicated space for all calculations, making it easier to find and manage them as your dashboard evolves.And your indicator table should look like the image below: Indicators Table 8.9 Bonus: Measures Used in This Chapter To complete the hands-on exercises in this chapter, create the following measures in the Measures table. Total Patient Visits Total Patient Visits := COUNTROWS ( fact_patient_visits ) Total ART Clients Total ART Clients := CALCULATE ( COUNTROWS ( fact_patient_visits ), fact_patient_visits[service_type] = &quot;ART&quot; ) Malaria Tests Conducted Malaria Tests Conducted := CALCULATE ( COUNTROWS ( fact_patient_visits ), fact_patient_visits[service_type] = &quot;Malaria Test&quot; ) TB Tests Conducted TB Tests Conducted := CALCULATE ( COUNTROWS ( fact_patient_visits ), fact_patient_visits[service_type] = &quot;TB Test&quot; ) These measures are intentionally simple. Their purpose is to support visual reasoning, not advanced DAX patterns. 8.10 Hands-On Practice: Choosing Visuals Deliberately Use the measures above to complete the following exercises. 8.10.1 Exercise 1: The 5-Second View Create KPI Card visuals for: Total Patient Visits Total ART Clients Malaria Tests Conducted TB Tests Conducted Place them in the top-left of the page. Reflection: Can someone understand performance instantly? 8.10.2 Exercise 2: Showing Direction Over Time Create a Line Chart: X-axis: Month or Quarter Y-axis: Total Patient Visits Observe how quickly trends become visible. 8.10.3 Exercise 3: Comparing Facilities Create a Horizontal Bar Chart: Category: Facility Value: Total Patient Visits Sort descending Now switch the visual to a Pie Chart and compare clarity. 8.10.4 Exercise 4: Ranking for Action Duplicate the bar chart and sort ascending to identify facilities needing support. 8.10.5 Exercise 5: Using Maps Responsibly Create a Map by district using Total Patient Visits. Place it next to a Bar Chart showing the same measure. Compare pattern recognition versus precision. 8.10.6 Exercise 6: Supporting Trust With Tables Create a Matrix visual with: Rows: Region → District → Facility Values: –Total Patient Visits – Total ART Clients Enable drill-down. 8.11 Avoiding Common Visualization Mistakes Be alert to these warning signs: Too many visuals on one page Excessive red and green coloring Pie charts used for comparison KPIs without context If a visual needs explanation, it is not doing its job. 8.11.1 Interaction Should Support Thinking Use interactivity intentionally: Cross-highlighting to explore relationships Drill-down to move from summary to detail Tooltips to add depth without clutter Disable confusing interactions using Edit Interactions when necessary. 8.11.2 A Simple Visual Selection Checklist Before finalizing any visual, ask: What question does this answer? Is this the simplest way to answer it? Can it be understood in seconds? Would a bar or table be clearer? When in doubt, choose clarity over creativity. 8.12 What to Carry Forward Good dashboards are quiet. They do not shout. They do not impress with decoration. They communicate clearly and invite action. When indicators are well defined and visuals are chosen deliberately, dashboards become trusted tools rather than presentation artifacts. The next chapter focuses on publishing and sharing dashboards responsibly, ensuring that the right people see the right information at the right level of detail. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
